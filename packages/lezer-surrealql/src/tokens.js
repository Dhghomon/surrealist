import { ExternalTokenizer } from "@lezer/lr";

import {
	assert,
	_break,
	_class,
	_continue,
	_default,
	_delete,
	_else,
	_false,
	_for,
	_function,
	_if,
	_in,
	_let,
	_null,
	_return,
	_throw,
	_true,
	_with,
	// Literals
	after,
	allinside,
	analyzer,
	and,
	any,
	anyinside,
	as,
	asc,
	ascii,
	at,
	before,
	begin,
	blank,
	bm25,
	by,
	camel,
	cancel,
	capacity,
	changefeed,
	changes,
	chebyshev,
	columns,
	comment,
	commit,
	contains,
	containsall,
	containsany,
	containsnone,
	containsnot,
	content,
	cosine,
	count,
	create,
	createPermissions,
	database,
	db,
	define,
	deletePermissions,
	desc,
	diff,
	dimension,
	dist,
	doc_ids_cache,
	doc_ids_order,
	doc_lengths_cache,
	doc_lengths_order,
	drop,
	duplicate,
	eddsa,
	edgengram,
	efc,
	end,
	es256,
	es384,
	es512,
	euclidean,
	event,
	exists,
	explain,
	extend_candidates,
	f32,
	f64,
	fetch,
	field,
	fields,
	filters,
	flexible,
	from,
	full,
	group,
	hamming,
	highlights,
	hnsw,
	i16,
	i32,
	i64,
	ignore,
	index,
	info,
	insert,
	inside,
	intersects,
	into,
	is,
	jaccard,
	jwks,
	keep_pruned_connections,
	key,
	kill,
	limit,
	live,
	lm,
	m,
	m0,
	manhattan,
	merge,
	minkowski,
	mtree,
	mtree_cache,
	namespace,
	ngram,
	noindex,
	none,
	noneinside,
	normal,
	not,
	notinside,
	ns,
	objectOpen,
	on,
	only,
	opIn,
	opNot,
	option,
	or,
	order,
	out,
	outside,
	parallel,
	param,
	passhash,
	password,
	patch,
	pearson,
	permissions,
	postings_cache,
	postings_order,
	ps256,
	ps384,
	ps512,
	punct,
	rand,
	readonly,
	rebuild,
	relate,
	relation,
	remove,
	roles,
	root,
	rs256,
	rs384,
	rs512,
	sc,
	schemafull,
	schemaless,
	scope,
	search,
	select,
	selectPermissions,
	session,
	set,
	show,
	signin,
	signup,
	since,
	sleep,
	snowball,
	split,
	start,
	structure,
	table,
	tb,
	terms_cache,
	terms_order,
	then,
	timeout,
	to,
	token,
	tokenizers,
	transaction,
	typeKeyword,
	unique,
	unset,
	update,
	updatePermissions,
	uppercase,
	use,
	user,
	valueKeyword,
	values,
	when,
	where,
} from "./parser.terms";

const tokenMap = {
	analyzer,
	any,
	as,
	asc,
	assert,
	at,
	begin,
	bm25,
	break: _break,
	by,
	cancel,
	capacity,
	changefeed,
	changes,
	columns,
	comment,
	commit,
	content,
	continue: _continue,
	create,
	database,
	db,
	default: _default,
	define,
	delete: _delete,
	desc,
	dimension,
	dist,
	doc_ids_cache,
	doc_ids_order,
	doc_lengths_cache,
	doc_lengths_order,
	drop,
	duplicate,
	efc,
	else: _else,
	end,
	exists,
	explain,
	extend_candidates,
	event,
	fetch,
	field,
	fields,
	filters,
	flexible,
	for: _for,
	from,
	group,
	highlights,
	hnsw,
	if: _if,
	ignore,
	in: _in,
	index,
	info,
	insert,
	into,
	keep_pruned_connections,
	key,
	kill,
	let: _let,
	limit,
	live,
	lm,
	m,
	m0,
	merge,
	mtree,
	mtree_cache,
	namespace,
	noindex,
	normal,
	not,
	ns,
	on,
	only,
	option,
	order,
	out,
	parallel,
	param,
	passhash,
	password,
	patch,
	permissions,
	postings_cache,
	postings_order,
	readonly,
	rebuild,
	relate,
	relation,
	remove,
	return: _return,
	roles,
	root,
	sc,
	scope,
	schemafull,
	schemaless,
	search,
	select,
	session,
	set,
	show,
	since,
	signin,
	signup,
	sleep,
	split,
	start,
	structure,
	tb,
	table,
	terms_cache,
	terms_order,
	then,
	throw: _throw,
	timeout,
	to,
	token,
	tokenizers,
	transaction,
	type: typeKeyword,
	unique,
	unset,
	update,
	use,
	user,
	value: valueKeyword,
	values,
	when,
	where,
	with: _with,

	// Literals
	after,
	before,
	diff,
	false: _false,
	full,
	none,
	null: _null,
	true: _true,

	f32,
	f64,
	i16,
	i32,
	i64,

	jwks,
	eddsa,
	es256,
	es384,
	es512,
	ps256,
	ps384,
	ps512,
	rs256,
	rs384,
	rs512,

	and,
	or,
	is,
	contains,
	containsnot,
	containsall,
	containsany,
	containsnone,
	inside,
	notinside,
	allinside,
	anyinside,
	noneinside,
	outside,
	intersects,

	chebyshev,
	cosine,
	euclidean,
	hamming,
	jaccard,
	manhattan,
	minkowski,
	pearson,

	ascii,
	edgengram,
	ngram,
	snowball,
	uppercase,

	blank,
	camel,
	class: _class,
	punct,

	// Function names
	function: _function,
	rand,
	count,
};

const tryMapped = {
	select: [selectPermissions],
	create: [createPermissions],
	update: [updatePermissions],
	delete: [deletePermissions],
	not: [opNot],
	in: [opIn],
};

export const tokens = function (t, stack) {
	for (const tk of tryMapped[t.toLowerCase()] ?? []) {
		if (stack.canShift(tk)) return tk;
	}

	return tokenMap[t.toLowerCase()] ?? -1;
};

function skipSpace(input, off) {
	for (;;) {
		let next = input.peek(off);
		if (next === 32 || next === 9 || next === 10 || next === 13) {
			off++;
		} else if (
			next === 35 /* '#' */ ||
			((next === 47 /* '/' */ || next === 45) /* '-' */ &&
				input.peek(off + 1) === next)
		) {
			off++;
			for (;;) {
				let next = input.peek(off);
				if (next < 0 || next === 10 || next === 13) break;
				off++;
			}
		} else {
			return off;
		}
	}
}

function isIdentifierChar(ch) {
	return (
		ch === 95 ||
		(ch >= 65 && ch <= 90) ||
		(ch >= 97 && ch <= 122) ||
		(ch >= 48 && ch <= 57)
	);
}

function skipObjKey(input, off) {
	let first = input.peek(off);
	if (isIdentifierChar(first)) {
		do {
			off++;
		} while (isIdentifierChar(input.peek(off)));
		return off;
	} else if (first === 38 /* "'" */ || first === 34 /* '"' */) {
		for (let escaped = false; ; ) {
			let next = input.peek(++off);
			if (next < 0) return off;
			if (next === first && !escaped) return off + 1;
			escaped = next === 92; /* '\\' */
		}
	}
}

export const objectToken = new ExternalTokenizer((input, _stack) => {
	if (input.next === 123 /* '{' */) {
		let off = skipSpace(input, 1);
		let key = skipObjKey(input, off);
		if (key !== null) {
			off = skipSpace(input, key);
			if (input.peek(off) === 58 /* ':' */) {
				input.acceptToken(objectOpen, 1);
			}
		}
	}
});
